{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahu0926/NVIDIA-PilotNet-Implementation/blob/main/NVIDIA_PilotNet_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAq6P63NpPPE"
      },
      "source": [
        "# NVIDIA PilotNet Implementation\n",
        "The goal of this code is to create an implementation of the popular end-to-end learning system of NVIDIA's PilotNet. \n",
        "\n",
        "[End to End Learning for Self Driving Cars](https://arxiv.org/pdf/1604.07316v1.pdf)\n",
        "\n",
        "[Explaining How a Deep Neural Network Trained with End-to-End Learning Steers a Car](https://arxiv.org/pdf/1704.07911v1.pdf)\n",
        "\n",
        "[Sully Chen's Autopilot Github](https://github.com/SullyChen/Autopilot-TensorFlow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixETG0gLblTu"
      },
      "source": [
        "Opening the Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5DEFjVgnUbL"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "!pip install gdown\n",
        "!gdown 1PZWa6H0i1PCH9zuYcIh5Ouk_p-9Gh58B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W49aTFZY4nnF"
      },
      "outputs": [],
      "source": [
        "!unzip 07012018.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWKIj3XCztPw"
      },
      "outputs": [],
      "source": [
        "# Importing everything\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfl\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "from keras.models import Sequential, save_model, load_model\n",
        "from keras.layers import Conv2D, MaxPooling2D \n",
        "from keras.layers import Activation, Dropout, Flatten, Dense \n",
        "import numpy as np\n",
        "from keras.callbacks import TensorBoard\n",
        "import time\n",
        "import datetime\n",
        "import cv2\n",
        "import os\n",
        "import tensorflow.keras\n",
        "from PIL import Image\n",
        "print('tf version', tf.__version__)\n",
        "print('keras version', tf.keras.__version__)\n",
        "print('gpu is ','available' if tf.config.list_physical_devices('GPU') else 'not available')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UI0Jftvu5fX-"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Reading data.txt - creating x, y, year, time variables\n",
        "x = []\n",
        "y = []\n",
        "year = []\n",
        "time = []\n",
        "with open(\"data.txt\") as f:\n",
        "  for line in f:\n",
        "    x.append(line.split()[0])\n",
        "    string = line.split()[1]\n",
        "    y.append((float(string.split(',')[0]) * 3.14159265 / 180))\n",
        "    year.append(string.split(',')[1])\n",
        "    time.append(line.split()[2])\n",
        "\n",
        "num_images = len(x)\n",
        "print(num_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoCvpc3_5VU0"
      },
      "outputs": [],
      "source": [
        "# Checking the image\n",
        "from PIL import Image\n",
        "filepath = \"data/9991.jpg\"\n",
        "Image.open(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc57XS8q4U1W"
      },
      "outputs": [],
      "source": [
        "# Creating Dataframes\n",
        "df = pd.DataFrame(list(zip(x, y)), columns =['imagepath', 'steering_command'])\n",
        "df_train = df.sample(frac=0.9)\n",
        "mask = df.imagepath.isin(df_train.imagepath)\n",
        "df_test = df[~mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQ_1mBUWBzJ_"
      },
      "outputs": [],
      "source": [
        "# Visualizing the data\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "fig = plt.figure(figsize=(20., 20.))\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(3, 3),\n",
        "                 axes_pad=0.5,\n",
        "                 label_mode=\"L\",\n",
        "                 )\n",
        "\n",
        "for ax, num in zip(grid, list(range(9))):\n",
        "    n = random.randint(0,len(df))\n",
        "    img = cv.imread(\"data/\" + df.imagepath[n])\n",
        "    #plt.figure(figsize = (10, 25))\n",
        "    ax.set_title(\"STEERING COMMAND: \" + str(df.steering_command[n]))\n",
        "    ax.imshow(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating histogram of y values\n",
        "plt.hist(df['steering_command'], bins=10, log=True)\n",
        "plt.title(\"Steering Angle Histogram\")\n",
        "plt.xlabel(\"Steering Angle Value\")\n",
        "plt.ylabel(\"Frequency\")"
      ],
      "metadata": {
        "id": "NIPqRk74zLu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAEnBFYuPEx1"
      },
      "outputs": [],
      "source": [
        "print(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8Qlyy9QvUxE"
      },
      "outputs": [],
      "source": [
        "# Creating Dataframe Iterators\n",
        "\n",
        "valsplit = 0.1\n",
        "BS = 100\n",
        "height = 455\n",
        "width = 256\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        validation_split = valsplit)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        df_train,\n",
        "        directory='data/',\n",
        "        x_col='imagepath',\n",
        "        y_col='steering_command',\n",
        "        target_size=(height, width),\n",
        "        batch_size=BS,\n",
        "        class_mode='raw',\n",
        "        subset = 'training'\n",
        "        )\n",
        "validation_generator = train_datagen.flow_from_dataframe(\n",
        "        df_train,\n",
        "        directory='data/',\n",
        "        x_col='imagepath',\n",
        "        y_col='steering_command',\n",
        "        target_size=(height, width),\n",
        "        batch_size=BS,\n",
        "        class_mode='raw',\n",
        "        subset = 'validation'\n",
        "        )\n",
        "test_generator=test_datagen.flow_from_dataframe(\n",
        "        df_test,\n",
        "        directory = 'data/',\n",
        "        x_col='imagepath',\n",
        "        y_col='steering_command',\n",
        "        target_size=(height, width),\n",
        "        batch_size=BS,\n",
        "        class_mode='raw',\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uE6bcED-hS4"
      },
      "source": [
        "Creating the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJtf4mZgx5h1"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential, save_model, load_model\n",
        "from keras.layers import Conv2D, MaxPooling2D \n",
        "from keras.layers import Activation, Dropout, Flatten, Dense \n",
        "from keras import backend as K\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import tensorflow as tf\n",
        "\n",
        "depth = 3\n",
        "\n",
        "inputShape = (height, width, depth)\n",
        "chanDim = -1\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    inputShape = (depth, height, width)\n",
        "    chanDim = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvVDMpw-9LFk"
      },
      "outputs": [],
      "source": [
        "# Pure PilotNet Paper Implementation \n",
        "model = Sequential()\n",
        "model.add(Conv2D(24, kernel_size=(5, 5), strides=(2, 2), padding=\"same\",input_shape=inputShape, activation=\"relu\"))\n",
        "model.add(Conv2D(36, kernel_size=(5, 5), strides=(2, 2), padding='same', activation=\"relu\"))\n",
        "model.add(Conv2D(48, kernel_size=(5, 5), strides=(2, 2), padding='same', activation=\"relu\"))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation=\"relu\"))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation=\"relu\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation=\"relu\"))\n",
        "model.add(Dense(50, activation=\"relu\"))\n",
        "model.add(Dense(10, activation=\"relu\"))\n",
        "model.add(Dense(1))\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PilotNet with Dropout\n",
        "model = Sequential()\n",
        "model.add(Conv2D(24, kernel_size=(5, 5), strides=(2, 2), padding=\"same\",input_shape=inputShape, activation=\"relu\"))\n",
        "model.add(Conv2D(36, kernel_size=(5, 5), strides=(2, 2), padding='same', activation=\"relu\"))\n",
        "model.add(Conv2D(48, kernel_size=(5, 5), strides=(2, 2), padding='same', activation=\"relu\"))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation=\"relu\"))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation=\"relu\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation=\"relu\"))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(50, activation=\"relu\"))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(10, activation=\"relu\"))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "_71DO3QyHDit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S-wTK-uwtvt"
      },
      "outputs": [],
      "source": [
        "# PilotNet with Batch Normalization\n",
        "n_classes = len(df.steering_command)\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(5, 5), strides=(2, 2), padding=\"same\",input_shape=inputShape))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(100, activation=\"relu\"))\n",
        "model.add(Dense(50, activation=\"relu\"))\n",
        "model.add(Dense(10, activation=\"relu\"))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP6lNIGH-lxo"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
        "rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience= 5, factor= 0.5, min_lr= 1e-6, verbose=1)\n",
        "\n",
        "model.compile(\n",
        "    loss='mse',\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "    #optimizer = 'adam',\n",
        "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYC0WWf84rKH"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=validation_generator,\n",
        "        steps_per_epoch=((1-valsplit)*len(df_train))//BS,\n",
        "        validation_steps = ((valsplit)*len(df_train))//BS,\n",
        "        epochs=15,\n",
        "        callbacks=[early_stop, rlrop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Lax1nAnEoHs"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rmse = history.history['root_mean_squared_error']\n",
        "val_rmse = history.history['val_root_mean_squared_error']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(rmse) + 1)\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, rmse, 'b', label='Training RMSE')\n",
        "plt.plot(epochs, val_rmse, 'r', label='Validation RMSE')\n",
        "plt.title('Training and Validation Root Mean Squared Error (RMSE)')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluate Test Set\")\n",
        "score = model.evaluate(test_generator)\n",
        "print(score)"
      ],
      "metadata": {
        "id": "T2zJXoyPbt7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "30X3P0VEd452"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "NVIDIA_PilotNet_Implementation.ipynb",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOxD/YTWTvBXMtTDT/WK2D",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}